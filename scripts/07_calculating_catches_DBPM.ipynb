{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0fc6a1-968c-467f-9a6c-5d15003d2364",
   "metadata": {},
   "source": [
    "# Calculating catches from gridded DBPM outputs\n",
    "**Author**: Denisse Fierro Arcos  \n",
    "**Date**: 2025-02-06  \n",
    "\n",
    "In this notebook, we will calculate catches from gridded DBPM outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83d314-52dc-40d2-a95c-cac096a6a101",
   "metadata": {},
   "source": [
    "## Loading relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deff782b-529b-4f09-86ba-020ad634a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/g/data/vf71/la6889/dbpm_southern_ocean/scripts/')\n",
    "import useful_functions as uf\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cft\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd8f5a-65ee-4ac2-b1f5-603eebe44715",
   "metadata": {},
   "source": [
    "## Start a cluster for parallelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b17868f-906d-490c-b4ca-b5965141ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c2ac5-dd94-499f-a499-5d8fc23f27f5",
   "metadata": {},
   "source": [
    "## Defining basic variables to run gridded DBPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771407fd-01ca-43e2-9cba-fd1e58d0835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of region and model resolution\n",
    "region = 'fao-58'\n",
    "model_res = '025deg'\n",
    "\n",
    "#Defining input and output folders\n",
    "base_folder = '/g/data/vf71/la6889/dbpm_inputs/east_antarctica'\n",
    "gridded_inputs = os.path.join(base_folder, 'gridded_params', model_res)\n",
    "gridded_outputs = os.path.join(base_folder, 'run_fishing', model_res)\n",
    "outputs_folder = os.path.join(base_folder, 'gridded_dbpm_outputs', model_res)\n",
    "\n",
    "#Ensure outputs folder exists\n",
    "os.makedirs(outputs_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd589e5-9199-4dbe-8b58-d1902e068439",
   "metadata": {},
   "source": [
    "## Loading gridded parameters and gridded inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f928b9-feb9-4fd6-8870-76c70ff7f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridded DBPM parameters\n",
    "gridded_params = json.load(open(\n",
    "    os.path.join(gridded_inputs, f'dbpm_gridded_size_params_{region}_python.json')))\n",
    "\n",
    "#Mortality from fishing (predators and detritivores)\n",
    "fish_mort_det = xr.open_zarr(glob(\n",
    "    os.path.join(gridded_inputs, 'fish-mort-det*'))[0])['fish_mort_det']\n",
    "fish_mort_pred = xr.open_zarr(glob(\n",
    "    os.path.join(gridded_inputs, 'fish-mort-pred*'))[0])['fish_mort_pred']\n",
    "\n",
    "#Effort - Only initialisation time step\n",
    "effort_init = xr.open_zarr(glob(\n",
    "    os.path.join(gridded_inputs, 'effort_spinup*'))[0])['effort'].isel(time = 0)\n",
    "\n",
    "#Size class bins\n",
    "log10_size_bins_mat = xr.open_zarr('outputs/log10_size_bins_matrix.zarr/')['size_bins']\n",
    "size_bin_vals = 10**log10_size_bins_mat\n",
    "\n",
    "#Area - to be used for masking land areas\n",
    "area = xr.open_zarr(glob(os.path.join(base_folder, 'gridded', model_res, \n",
    "                                      '*areacello*'))[0])['cellareao']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a33f7-25dd-4a9d-bd5e-3d6c3a5af894",
   "metadata": {},
   "source": [
    "## Loading gridded DBPM outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94b4bef-80e3-4375-95e2-06e75d563635",
   "metadata": {},
   "outputs": [],
   "source": [
    "predators = xr.open_mfdataset(glob(\n",
    "    os.path.join(gridded_outputs, 'predators*')))['predators']\n",
    "\n",
    "detritivores = xr.open_mfdataset(glob(\n",
    "    os.path.join(gridded_outputs, 'detritivores*')))['detritivores']\n",
    "\n",
    "effort = xr.open_mfdataset(glob(os.path.join(gridded_outputs, 'effort*')))['effort']\n",
    "\n",
    "#Add initial effort values\n",
    "effort = xr.concat([effort_init, effort], dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09aa79e-6a05-416c-86c8-23dfb996f917",
   "metadata": {},
   "source": [
    "## Calculate fishing mortality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425236e0-f84a-423b-9ff5-253b38251fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fishing_mort_pred = fish_mort_pred*effort\n",
    "fishing_mort_det = fish_mort_det*effort "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd886c-29f0-4008-9e63-07d99e6a8279",
   "metadata": {},
   "source": [
    "## Calculates catches per time step and size class\n",
    "`fishing_mort_pred` and `fishing_mort_det` are set to zero outside the sizes for each class, so there is no need to apply a mask here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54340d9-e8e4-45e8-bafc-7a3c15610c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_pred = fishing_mort_pred*predators*size_bin_vals\n",
    "catch_det = fishing_mort_det*detritivores*size_bin_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862bc2b-d1fa-4849-96ab-83c06cabf41f",
   "metadata": {},
   "source": [
    "## Calculate pelagic predator and benthic detritivore catches from DBPM outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf70da81-9ee1-45a2-8ef7-90efec30e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate total catches for detritivores and predators \n",
    "# That is we add catches across all fished size classes\n",
    "tot_catch_pred = (catch_pred*gridded_params['log_size_increase']).sum('size_class')\n",
    "tot_catch_det = (catch_det*gridded_params['log_size_increase']).sum('size_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed417984-4258-496c-82a0-65a8a2668664",
   "metadata": {},
   "source": [
    "### Calculate mean decadal catches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97e0b3e-5061-44ee-9a6d-ba7035824e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predator catches\n",
    "mean_catch_pred_dec = uf.decadal_catches(\n",
    "    tot_catch_pred, area, name = 'catch_predators',\n",
    "    attrs = {'units': 'g*decade-1*m-2', \n",
    "             'long_name': 'mean predators biomass caught per decade'})\n",
    "\n",
    "#Detritivore catches\n",
    "mean_catch_det_dec = uf.decadal_catches(\n",
    "    tot_catch_det, area, name = 'catch_detritivores',\n",
    "    attrs = {'units': 'g*decade-1*m-2', \n",
    "             'long_name': 'mean detritivores biomass caught per decade'})\n",
    "\n",
    "#Total catches\n",
    "sum_catch_dec = mean_catch_pred_dec + mean_catch_det_dec\n",
    "sum_catch_dec.name = 'catch_total'\n",
    "sum_catch_dec = sum_catch_dec.assign_attrs({'units': 'g*decade-1*m-2', \n",
    "                                            'long_name': 'mean biomass caught per decade'})\n",
    "\n",
    "#Store catches in a single dataset\n",
    "mean_catch_dec = xr.Dataset(data_vars = {'catch_det': mean_catch_det_dec,\n",
    "                                         'catch_pred': mean_catch_pred_dec,\n",
    "                                         'catch_sum': sum_catch_dec})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5fc11-536d-4224-85b4-81c01808c6dd",
   "metadata": {},
   "source": [
    "### Saving catches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecd34c8-a67a-4bce-8913-0afdd05e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get start and end decade\n",
    "s_dec = str(mean_catch_dec.decade.values.min())\n",
    "e_dec = str(mean_catch_dec.decade.values.max())\n",
    "\n",
    "#Create filename to save results\n",
    "fout = os.path.join(outputs_folder,\n",
    "                    f'mean_decadal_catches_{model_res}_{region}_{s_dec}_{e_dec}.nc')\n",
    "\n",
    "#Saving dataset\n",
    "mean_catch_dec.to_netcdf(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98140d-6bfa-4463-b8be-b223947532f5",
   "metadata": {},
   "source": [
    "### *Optional*: Load catches if previously processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1663e83-58b7-4135-8fec-c01e6ecea783",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_catch_dec = xr.open_dataset(\n",
    "    glob(os.path.join(outputs_folder,\n",
    "                      f'mean_decadal_catches_{model_res}_{region}_*.nc'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d80ee6-80ec-4957-94f9-41fce4550251",
   "metadata": {},
   "source": [
    "## Calculating weighted mean for yearly catches from DBPM outputs (time series)\n",
    "To make results comparable to outputs from the non-spatial DBPM, we will calculate the weighted mean for catches per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a6f073-6f54-4313-80d4-b3ddee999702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now calculate the total catch\n",
    "total_catch = tot_catch_det+tot_catch_pred\n",
    "total_catch.name = 'mean_catch'\n",
    "\n",
    "# Creating weights from grid cell area \n",
    "weights = area.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55123713-7b64-4d6b-b4f1-4d8e41c01b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we calculate the mean yearly catch\n",
    "catch_weighted_mean = []\n",
    "\n",
    "#We will group data by year first and then calculate the weighted mean\n",
    "for yr, d in total_catch.groupby('time.year'):\n",
    "    d_weighted = d.weighted(weights)\n",
    "    dw_mean = d_weighted.mean(('time', 'lat', 'lon')).expand_dims({'year': [yr]})\n",
    "    catch_weighted_mean.append(dw_mean)\n",
    "\n",
    "catch_weighted_mean = xr.concat(catch_weighted_mean, dim = 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aad66fc7-f3b6-4bfe-bce2-39be54668af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming to data frame\n",
    "catch_weighted_mean = catch_weighted_mean.to_pandas().reset_index()\n",
    "# Adding units \n",
    "catch_weighted_mean['units'] = 'g*year-1*m-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75712f89-2da3-4c9c-9d28-942d65c0fd21",
   "metadata": {},
   "source": [
    "### Saving mean catches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e45977-441a-4de4-9076-22dcef5f1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting min and max year from data\n",
    "min_yr = str(catch_weighted_mean.year.min())\n",
    "max_yr = str(catch_weighted_mean.year.max())\n",
    "\n",
    "# Creating name for file \n",
    "out_name = f'mean_year_catch_dbpm_{model_res}_{region}_{min_yr}-{max_yr}.parquet'\n",
    "\n",
    "# Saving in output folder\n",
    "catch_weighted_mean.to_parquet(os.path.join(outputs_folder, out_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.07]",
   "language": "python",
   "name": "conda-env-analysis3-24.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
